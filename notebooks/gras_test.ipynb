{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invd_sparse(x):\n",
    "    \"\"\"\n",
    "    Constructs a diagonal matrix with 1/x, replacing entries where x == 0 with 1.\n",
    "    \n",
    "    Parameters:\n",
    "        x (numpy array): Input 1D array.\n",
    "        \n",
    "    Returns:\n",
    "        numpy array: A diagonal matrix.\n",
    "    \"\"\"\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        invd_values = np.where(x != 0, 1.0 / x, 1.0)\n",
    "    return sp.diags(invd_values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRAS_UpdateMatrix(P,N, r, s):\n",
    "    \"\"\"\n",
    "    Updates the matrix using the GRAS balancing approach.\n",
    "    \"\"\"\n",
    "    return np.diag(r.flatten()) @ P @ np.diag(s.flatten())-invd(r) @ N @ invd(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import warnings\n",
    "\n",
    "def invd_sparse(x):\n",
    "    \"\"\"\n",
    "    Constructs a diagonal sparse matrix with 1/x, replacing entries where x == 0 with 1.\n",
    "    \n",
    "    Parameters:\n",
    "        x (numpy array or scipy sparse matrix): Input 1D array.\n",
    "        \n",
    "    Returns:\n",
    "        scipy sparse matrix: A diagonal sparse matrix.\n",
    "    \"\"\"\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        invd_values = np.where(x != 0, 1.0 / x, 1.0)\n",
    "    return sp.diags(invd_values.flatten())\n",
    "\n",
    "def GRAS_UpdateMatrix(P, N, r, s):\n",
    "    \"\"\"\n",
    "    Updates the matrix using the GRAS balancing approach with sparse matrices.\n",
    "    \n",
    "    Parameters:\n",
    "        P (scipy sparse matrix): Positive part of the input matrix.\n",
    "        N (scipy sparse matrix): Negative part of the input matrix.\n",
    "        r (numpy array): Row adjustment factors.\n",
    "        s (numpy array): Column adjustment factors.\n",
    "        \n",
    "    Returns:\n",
    "        scipy sparse matrix: The updated balanced matrix.\n",
    "    \"\"\"\n",
    "    return sp.diags(r.flatten()) @ P @ sp.diags(s.flatten()) - invd_sparse(r) @ N @ invd_sparse(s)\n",
    "\n",
    "def GRAS_Balancing(X, u, v, EPSILON=1e-10, max_iter=20):\n",
    "    # Ensure inputs are consistent\n",
    "    assert np.allclose(u.sum(), v.sum()), \"Row and column sums must be equal.\"\n",
    "\n",
    "    # Define matrix size\n",
    "    m, n = X.shape\n",
    "\n",
    "    # Split into positive and negative components (in sparse format)\n",
    "    P = sp.csr_matrix(np.maximum(X, 0))\n",
    "    N = sp.csr_matrix(np.maximum(-X, 0))\n",
    "    assert np.allclose(X, (P - N).toarray()), \"Matrix decomposition into P and N is incorrect.\"\n",
    "\n",
    "    # Initialize vectors\n",
    "    r = np.ones((m, 1))\n",
    "    pr = P.T @ r\n",
    "    nr = N.T @ invd_sparse(r) @ np.ones((m, 1))\n",
    "\n",
    "    # Initial value of s1\n",
    "    # Ensure pr and nr are compatible for element-wise multiplication\n",
    "    pr_dense = pr.toarray() if sp.issparse(pr) else pr\n",
    "    nr_dense = nr.toarray() if sp.issparse(nr) else nr\n",
    "    s1 = invd_sparse(2 * pr_dense) @ (v + np.sqrt(v ** 2 + 4 * pr_dense * nr_dense))\n",
    "    \n",
    "    # Handle possible NaNs\n",
    "    s1 = np.nan_to_num(s1, nan=1e-10, posinf=1e-10, neginf=1e-10)\n",
    "\n",
    "    ss = -invd_sparse(v) @ nr\n",
    "    s1[pr_dense.flatten() == 0] = ss[pr_dense.flatten() == 0]\n",
    "\n",
    "    # Iteration loop\n",
    "    iter = 1\n",
    "    dif = float('inf')\n",
    "\n",
    "    while (dif > EPSILON) and (iter <= max_iter):\n",
    "        # Update r\n",
    "        ps = P @ s1\n",
    "        ns = N @ invd_sparse(s1) @ np.ones((n, 1))\n",
    "\n",
    "        ps_dense = ps.toarray() if sp.issparse(ps) else ps\n",
    "        ns_dense = ns.toarray() if sp.issparse(ns) else ns\n",
    "        r = invd_sparse(2 * ps_dense) @ (u + np.sqrt(u ** 2 + 4 * ps_dense * ns_dense))\n",
    "        \n",
    "        # Handle possible NaNs\n",
    "        r = np.nan_to_num(r, nan=1e-10, posinf=1e-10, neginf=1e-10)\n",
    "\n",
    "        rr = -invd_sparse(u) @ ns\n",
    "        r[ps_dense.flatten() == 0] = rr[ps_dense.flatten() == 0]\n",
    "\n",
    "        # Update s2\n",
    "        pr = P.T @ r\n",
    "        nr = N.T @ invd_sparse(r) @ np.ones((m, 1))\n",
    "        \n",
    "        pr_dense = pr.toarray() if sp.issparse(pr) else pr\n",
    "        nr_dense = nr.toarray() if sp.issparse(nr) else nr\n",
    "        s2 = invd_sparse(2 * pr_dense) @ (v + np.sqrt(v ** 2 + 4 * pr_dense * nr_dense))\n",
    "\n",
    "        # Handle possible NaNs\n",
    "        s2 = np.nan_to_num(s2, nan=1e-10, posinf=1e-10, neginf=1e-10)\n",
    "        \n",
    "        ss = -invd_sparse(v) @ nr\n",
    "        s2[pr_dense.flatten() == 0] = ss[pr_dense.flatten() == 0]\n",
    "\n",
    "        # Convergence check\n",
    "        dif = np.max(np.abs(s2 - s1))\n",
    "        s1 = s2  # Update s1 for next iteration\n",
    "    \n",
    "\n",
    "    # Post iteration checks\n",
    "    if (iter == max_iter) and (dif > EPSILON ):\n",
    "        warnings.warn(\"GRAS procedure did not converge.\")\n",
    "        return None\n",
    "    else:\n",
    "        s = s2\n",
    "        ps = P @ s\n",
    "        ns = N @ invd_sparse(s) @ np.ones((n, 1))\n",
    "        \n",
    "        ps_dense = ps.toarray() if sp.issparse(ps) else ps\n",
    "        ns_dense = ns.toarray() if sp.issparse(ns) else ns\n",
    "        r = invd_sparse(2 * ps_dense) @ (u + np.sqrt(u ** 2 + 4 * ps_dense * ns_dense))\n",
    "\n",
    "        # Handle possible NaNs\n",
    "        r = np.nan_to_num(r, nan=1e-10, posinf=1e-10, neginf=1e-10)\n",
    "        \n",
    "        rr = -invd_sparse(u) @ ns\n",
    "        r[ps_dense.flatten() == 0] = rr[ps_dense.flatten() == 0]\n",
    "\n",
    "        # Final updated matrix\n",
    "        return GRAS_UpdateMatrix(P, N, r, s), iter, dif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "m,n = (10,50)\n",
    "\n",
    "EPSILON = 1e-14\n",
    "\n",
    "X = (np.random.rand(m,n)-0.5)\n",
    "\n",
    "v, u = X.sum(axis = 0), X.sum(axis = 1)\n",
    "\n",
    "v = v.reshape((n,1))\n",
    "u = u.reshape((m,1))\n",
    "\n",
    "assert np.allclose(u.sum(),v.sum())\n",
    "\n",
    "u[0,0]=u[0,0]+1\n",
    "v[0,0]=v[0,0]+1\n",
    "\n",
    "assert np.allclose(u.sum(),v.sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, _ , _ = GRAS_Balancing(X, u, v, EPSILON=EPSILON, max_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1: Small Basic Matrix\n",
      "Test Case 1 passed: Converged in 1 iterations with final difference 7.62496732420459e-11\n"
     ]
    }
   ],
   "source": [
    "# Test Case 1: Small Basic Matrix\n",
    "print(\"Test Case 1: Small Basic Matrix\")\n",
    "X1 = np.array([[5, -3, 0], [2, 0, -2], [-1, 3, 4]])\n",
    "u1 = np.array([4, 3, 5]).reshape(-1, 1)\n",
    "v1 = np.array([3, 4, 5]).reshape(-1, 1)\n",
    "result1, iterations1, diff1 = GRAS_Balancing(X1, u1, v1)\n",
    "\n",
    "assert result1 is not None, \"Test Case 1 failed: Procedure did not converge.\"\n",
    "assert np.allclose(np.array(result1.sum(axis=1)).flatten(), u1.flatten(), atol=1e-5), \"Test Case 1 failed: Row sums do not match.\"\n",
    "assert np.allclose(np.array(result1.sum(axis=0)).flatten(), v1.flatten(), atol=1e-5), \"Test Case 1 failed: Column sums do not match.\"\n",
    "# Check if the sign of each element is preserved\n",
    "assert np.all((X1 > 0) == (result1 > 0)), \"Test Case 1 failed: Signs of positive cells are not preserved.\"\n",
    "assert np.all((X1 < 0) == (result1 < 0)), \"Test Case 1 failed: Signs of negative cells are not preserved.\"\n",
    "print(f\"Test Case 1 passed: Converged in {iterations1} iterations with final difference {diff1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Case 2: Diagonal Matrix\n",
      "Test Case 2 passed: Converged in 1 iterations with final difference 0.0\n"
     ]
    }
   ],
   "source": [
    "# Test Case 2: Diagonal Matrix\n",
    "print(\"\\nTest Case 2: Diagonal Matrix\")\n",
    "X2 = np.array([[5, 0, 0], [0, -4, 0], [0, 0, 3]])\n",
    "u2 = np.array([5, -4, 3]).reshape(-1, 1)\n",
    "v2 = np.array([5, -4, 3]).reshape(-1, 1)\n",
    "result2, iterations2, diff2 = GRAS_Balancing(X2, u2, v2)\n",
    "assert result2 is not None, \"Test Case 2 failed: Procedure did not converge.\"\n",
    "assert np.allclose(np.array(result2.sum(axis=1)).flatten(), u2.flatten(), atol=1e-5), \"Test Case 2 failed: Row sums do not match.\"\n",
    "assert np.allclose(np.array(result2.sum(axis=0)).flatten(), v2.flatten(), atol=1e-5), \"Test Case 2 failed: Column sums do not match.\"\n",
    "# Check if the sign of each element is preserved\n",
    "assert np.all((X2 > 0) == (result2 > 0)), \"Test Case 2 failed: Signs of positive cells are not preserved.\"\n",
    "assert np.all((X2 < 0) == (result2 < 0)), \"Test Case 2 failed: Signs of negative cells are not preserved.\"\n",
    "print(f\"Test Case 2 passed: Converged in {iterations2} iterations with final difference {diff2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Case 3: All Positive Matrix\n",
      "Test Case 3 passed: Converged in 1 iterations with final difference 9.164669023675742e-11\n"
     ]
    }
   ],
   "source": [
    "# Test Case 3: All Positive Matrix\n",
    "print(\"\\nTest Case 3: All Positive Matrix\")\n",
    "X3 = np.array([[3, 2, 1], [4, 5, 6], [7, 8, 9]])\n",
    "u3 = np.array([7, 16, 24]).reshape(-1, 1)\n",
    "v3 = np.array([21, 15, 11]).reshape(-1, 1)\n",
    "result3, iterations3, diff3 = GRAS_Balancing(X3, u3, v3)\n",
    "assert result3 is not None, \"Test Case 3 failed: Procedure did not converge.\"\n",
    "assert np.allclose(np.array(result3.sum(axis=1)).flatten(), u3.flatten(), atol=1e-5), \"Test Case 3 failed: Row sums do not match.\"\n",
    "assert np.allclose(np.array(result3.sum(axis=0)).flatten(), v3.flatten(), atol=1e-5), \"Test Case 3 failed: Column sums do not match.\"\n",
    "# Check if the sign of each element is preserved\n",
    "assert np.all((X3 > 0) == (result3 > 0)), \"Test Case 3 failed: Signs of positive cells are not preserved.\"\n",
    "print(f\"Test Case 3 passed: Converged in {iterations3} iterations with final difference {diff3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Case 4: Large Sparse Matrix\n",
      "Test Case 4 passed: Converged in 1 iterations with final difference 8.776268600740877e-11\n"
     ]
    }
   ],
   "source": [
    "# Test Case 4: Large Sparse Matrix\n",
    "print(\"\\nTest Case 4: Large Sparse Matrix\")\n",
    "X4 = sp.random(100, 100, density=0.1, format='csr') - sp.random(100, 100, density=0.1, format='csr')\n",
    "u4 = np.random.rand(100, 1) * 10\n",
    "v4 = np.random.rand(100, 1) * 10\n",
    "u4 = u4 / u4.sum() * v4.sum()  # Normalize u4 to ensure u4.sum() == v4.sum()\n",
    "result4, iterations4, diff4 = GRAS_Balancing(X4.toarray(), u4, v4)\n",
    "assert result4 is not None, \"Test Case 4 failed: Procedure did not converge.\"\n",
    "assert np.allclose(np.nan_to_num(np.array(result4.sum(axis = 1)).flatten()), u4.flatten(), atol=1e-5), \"Test Case 4 failed: Row sums do not match.\"\n",
    "assert np.allclose(np.nan_to_num(np.array(result4.sum(axis=0)).flatten()), v4.flatten(), atol=1e-5), \"Test Case 4 failed: Column sums do not match.\"\n",
    "# Check if the sign of each element is preserved\n",
    "assert np.all((X4.toarray() > 0) == (result4 > 0)), \"Test Case 4 failed: Signs of positive cells are not preserved.\"\n",
    "assert np.all((X4.toarray() < 0) == (result4 < 0)), \"Test Case 4 failed: Signs of negative cells are not preserved.\"\n",
    "print(f\"Test Case 4 passed: Converged in {iterations4} iterations with final difference {diff4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
